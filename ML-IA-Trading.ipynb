{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a926d927-6143-4529-8ca5-cc266566fcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• T√©l√©chargement des donn√©es en 1h par batch...\n",
      " - T√©l√©chargement de 2024-01-01 √† 2024-01-11...\n",
      " - T√©l√©chargement de 2024-01-12 √† 2024-01-22...\n",
      " - T√©l√©chargement de 2024-01-23 √† 2024-02-02...\n",
      " - T√©l√©chargement de 2024-02-03 √† 2024-02-13...\n",
      " - T√©l√©chargement de 2024-02-14 √† 2024-02-24...\n",
      " - T√©l√©chargement de 2024-02-25 √† 2024-03-06...\n",
      " - T√©l√©chargement de 2024-03-07 √† 2024-03-17...\n",
      " - T√©l√©chargement de 2024-03-18 √† 2024-03-28...\n",
      " - T√©l√©chargement de 2024-03-29 √† 2024-04-08...\n",
      "Erreur: {'code': 429, 'message': 'You have run out of API credits for the current minute. 9 API credits were used, with the current limit being 8. Wait for the next minute or consider switching to a higher tier plan at https://twelvedata.com/pricing', 'status': 'error'}\n",
      " - T√©l√©chargement de 2024-04-09 √† 2024-04-19...\n",
      "Erreur: {'code': 429, 'message': 'You have run out of API credits for the current minute. 10 API credits were used, with the current limit being 8. Wait for the next minute or consider switching to a higher tier plan at https://twelvedata.com/pricing', 'status': 'error'}\n",
      " - T√©l√©chargement de 2024-04-20 √† 2024-04-30...\n",
      "Erreur: {'code': 429, 'message': 'You have run out of API credits for the current minute. 11 API credits were used, with the current limit being 8. Wait for the next minute or consider switching to a higher tier plan at https://twelvedata.com/pricing', 'status': 'error'}\n",
      " - T√©l√©chargement de 2024-05-01 √† 2024-05-11...\n",
      "Erreur: {'code': 429, 'message': 'You have run out of API credits for the current minute. 12 API credits were used, with the current limit being 8. Wait for the next minute or consider switching to a higher tier plan at https://twelvedata.com/pricing', 'status': 'error'}\n",
      " - T√©l√©chargement de 2024-05-12 √† 2024-05-22...\n",
      "Erreur: {'code': 429, 'message': 'You have run out of API credits for the current minute. 13 API credits were used, with the current limit being 8. Wait for the next minute or consider switching to a higher tier plan at https://twelvedata.com/pricing', 'status': 'error'}\n",
      " - T√©l√©chargement de 2024-05-23 √† 2024-06-02...\n",
      "Erreur: {'code': 429, 'message': 'You have run out of API credits for the current minute. 14 API credits were used, with the current limit being 8. Wait for the next minute or consider switching to a higher tier plan at https://twelvedata.com/pricing', 'status': 'error'}\n",
      " - T√©l√©chargement de 2024-06-03 √† 2024-06-13...\n",
      "Erreur: {'code': 429, 'message': 'You have run out of API credits for the current minute. 15 API credits were used, with the current limit being 8. Wait for the next minute or consider switching to a higher tier plan at https://twelvedata.com/pricing', 'status': 'error'}\n",
      " - T√©l√©chargement de 2024-06-14 √† 2024-06-24...\n",
      "Erreur: {'code': 429, 'message': 'You have run out of API credits for the current minute. 16 API credits were used, with the current limit being 8. Wait for the next minute or consider switching to a higher tier plan at https://twelvedata.com/pricing', 'status': 'error'}\n",
      " - T√©l√©chargement de 2024-06-25 √† 2024-06-30...\n",
      "Erreur: {'code': 429, 'message': 'You have run out of API credits for the current minute. 17 API credits were used, with the current limit being 8. Wait for the next minute or consider switching to a higher tier plan at https://twelvedata.com/pricing', 'status': 'error'}\n",
      "‚úÖ Donn√©es t√©l√©charg√©es. Nettoyage...\n",
      "‚úÖ Calcul des indicateurs techniques...\n",
      "‚úÖ Cr√©ation des targets (classification et r√©gressions)...\n",
      "              datetime       close  target  target_up_move  target_down_move\n",
      "25 2024-01-03 01:00:00  2062.46997       1         2.29004           0.81006\n",
      "26 2024-01-03 02:00:00  2064.76001       1         0.39990           1.33008\n",
      "27 2024-01-03 03:00:00  2065.15991       0        -0.22998           0.64990\n",
      "28 2024-01-03 04:00:00  2064.92993       0        -0.79004           1.35986\n",
      "29 2024-01-03 05:00:00  2064.13989       1         0.22022           0.60986\n",
      "‚úÖ Donn√©es sauvegard√©es dans gold_features_hourly_with_tp_sl.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import ta\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "api_key = 'f5754d3325dc4149ba98663c7dd9821e'\n",
    "symbol = 'XAU/USD'\n",
    "interval = '1h'\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-06-30'\n",
    "\n",
    "# === Helper : t√©l√©charger une page de donn√©es ===\n",
    "def fetch_data_page(start_date, end_date):\n",
    "    url = 'https://api.twelvedata.com/time_series'\n",
    "    params = {\n",
    "        'symbol': symbol,\n",
    "        'interval': interval,\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'apikey': api_key,\n",
    "        'format': 'JSON',\n",
    "        'order': 'ASC',\n",
    "        'timezone': 'UTC',\n",
    "        'outputsize': 5000\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    if 'values' in data:\n",
    "        return pd.DataFrame(data['values'])\n",
    "    else:\n",
    "        print(\"Erreur:\", data)\n",
    "        return None\n",
    "\n",
    "# === Boucle sur l'historique ===\n",
    "all_data = pd.DataFrame()\n",
    "current_start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "final_end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "print(\"üì• T√©l√©chargement des donn√©es en 1h par batch...\")\n",
    "\n",
    "while current_start < final_end:\n",
    "    current_end = current_start + timedelta(days=10)\n",
    "    if current_end > final_end:\n",
    "        current_end = final_end\n",
    "\n",
    "    print(f\" - T√©l√©chargement de {current_start.date()} √† {current_end.date()}...\")\n",
    "    df_page = fetch_data_page(current_start.strftime(\"%Y-%m-%d\"), current_end.strftime(\"%Y-%m-%d\"))\n",
    "    if df_page is not None and not df_page.empty:\n",
    "        all_data = pd.concat([all_data, df_page])\n",
    "\n",
    "    current_start = current_end + timedelta(days=1)\n",
    "    time.sleep(1)\n",
    "\n",
    "# === Nettoyage ===\n",
    "if all_data.empty:\n",
    "    print(\"‚ùå ERREUR : aucune donn√©e t√©l√©charg√©e.\")\n",
    "    exit()\n",
    "\n",
    "print(\"‚úÖ Donn√©es t√©l√©charg√©es. Nettoyage...\")\n",
    "\n",
    "all_data['datetime'] = pd.to_datetime(all_data['datetime'])\n",
    "all_data = all_data.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "# Colonnes num√©riques\n",
    "for col in ['open', 'high', 'low', 'close']:\n",
    "    all_data[col] = all_data[col].astype(float)\n",
    "\n",
    "# === Calcul des indicateurs ===\n",
    "print(\"‚úÖ Calcul des indicateurs techniques...\")\n",
    "\n",
    "close_series = all_data['close']\n",
    "\n",
    "all_data['rsi'] = ta.momentum.RSIIndicator(close_series, window=10).rsi()\n",
    "all_data['ema_9'] = close_series.ewm(span=9, adjust=False).mean()\n",
    "all_data['ema_21'] = close_series.ewm(span=21, adjust=False).mean()\n",
    "macd_calc = ta.trend.MACD(close_series)\n",
    "all_data['macd_line'] = macd_calc.macd()\n",
    "\n",
    "# === Cr√©er les targets ===\n",
    "print(\"‚úÖ Cr√©ation des targets (classification et r√©gressions)...\")\n",
    "\n",
    "# Classification : binaire (up ou down)\n",
    "all_data['target'] = (all_data['close'].shift(-1) > all_data['close']).astype(int)\n",
    "\n",
    "# R√©gressions : amplitude attendue\n",
    "all_data['target_up_move'] = all_data['close'].shift(-1) - all_data['close']\n",
    "all_data['target_down_move'] = all_data['close'] - all_data['low'].shift(-1)\n",
    "\n",
    "# Nettoyage final\n",
    "all_data = all_data.dropna()\n",
    "\n",
    "# ‚úÖ Affichage d'exemple\n",
    "print(all_data[['datetime', 'close', 'target', 'target_up_move', 'target_down_move']].head())\n",
    "\n",
    "# === Sauvegarde CSV ===\n",
    "all_data.to_csv('gold_features_hourly_with_tp_sl.csv', index=False)\n",
    "print(\"‚úÖ Donn√©es sauvegard√©es dans gold_features_hourly_with_tp_sl.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66a8405-8ead-4045-b175-97490450a2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              datetime         open        high         low       close  \\\n",
      "0  2024-01-03 01:00:00  2060.139890  2062.61011  2059.63989  2062.46997   \n",
      "1  2024-01-03 02:00:00  2062.639890  2065.21997  2061.65991  2064.76001   \n",
      "2  2024-01-03 03:00:00  2064.739990  2065.65991  2063.42993  2065.15991   \n",
      "3  2024-01-03 04:00:00  2065.070068  2065.63989  2064.51001  2064.92993   \n",
      "4  2024-01-03 05:00:00  2064.909910  2066.01001  2063.57007  2064.13989   \n",
      "\n",
      "         rsi        ema_9       ema_21  macd_line  target  target_up_move  \\\n",
      "0  46.534320  2061.784961  2064.079983  -1.938432       1         2.29004   \n",
      "1  52.071399  2062.379971  2064.141804  -1.619057       1         0.39990   \n",
      "2  53.015517  2062.935959  2064.234359  -1.318482       0        -0.22998   \n",
      "3  52.356498  2063.334753  2064.297593  -1.086310       0        -0.79004   \n",
      "4  49.984852  2063.495780  2064.283256  -0.955052       1         0.22022   \n",
      "\n",
      "   target_down_move  \n",
      "0           0.81006  \n",
      "1           1.33008  \n",
      "2           0.64990  \n",
      "3           1.35986  \n",
      "4           0.60986  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('gold_features_hourly_with_tp_sl.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfd49aa-5d75-4598-aca1-62c971b10d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1275 entries, 0 to 1274\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   datetime          1275 non-null   object \n",
      " 1   open              1275 non-null   float64\n",
      " 2   high              1275 non-null   float64\n",
      " 3   low               1275 non-null   float64\n",
      " 4   close             1275 non-null   float64\n",
      " 5   rsi               1275 non-null   float64\n",
      " 6   ema_9             1275 non-null   float64\n",
      " 7   ema_21            1275 non-null   float64\n",
      " 8   macd_line         1275 non-null   float64\n",
      " 9   target            1275 non-null   int64  \n",
      " 10  target_up_move    1275 non-null   float64\n",
      " 11  target_down_move  1275 non-null   float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 119.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b579a1c2-b02d-4c26-97cc-37abd2100b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es charg√©es\n",
      "              datetime         open        high         low       close  \\\n",
      "0  2024-01-03 01:00:00  2060.139890  2062.61011  2059.63989  2062.46997   \n",
      "1  2024-01-03 02:00:00  2062.639890  2065.21997  2061.65991  2064.76001   \n",
      "2  2024-01-03 03:00:00  2064.739990  2065.65991  2063.42993  2065.15991   \n",
      "3  2024-01-03 04:00:00  2065.070068  2065.63989  2064.51001  2064.92993   \n",
      "4  2024-01-03 05:00:00  2064.909910  2066.01001  2063.57007  2064.13989   \n",
      "\n",
      "         rsi        ema_9       ema_21  macd_line  target  target_up_move  \\\n",
      "0  46.534320  2061.784961  2064.079983  -1.938432       1         2.29004   \n",
      "1  52.071399  2062.379971  2064.141804  -1.619057       1         0.39990   \n",
      "2  53.015517  2062.935959  2064.234359  -1.318482       0        -0.22998   \n",
      "3  52.356498  2063.334753  2064.297593  -1.086310       0        -0.79004   \n",
      "4  49.984852  2063.495780  2064.283256  -0.955052       1         0.22022   \n",
      "\n",
      "   target_down_move  \n",
      "0           0.81006  \n",
      "1           1.33008  \n",
      "2           0.64990  \n",
      "3           1.35986  \n",
      "4           0.60986  \n",
      "‚úÖ Split des donn√©es effectu√©\n",
      "‚úÖ Entra√Ænement termin√©\n",
      "\n",
      "‚úÖ Classifier Accuracy: 0.5176470588235295\n",
      "\n",
      "‚úÖ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.45      0.48       124\n",
      "           1       0.53      0.58      0.55       131\n",
      "\n",
      "    accuracy                           0.52       255\n",
      "   macro avg       0.52      0.52      0.51       255\n",
      "weighted avg       0.52      0.52      0.52       255\n",
      "\n",
      "\n",
      "‚úÖ MAE Take-Profit: 2.105762094941177\n",
      "\n",
      "‚úÖ MAE Stop-Loss: 1.4624770166666694\n",
      "\n",
      "‚úÖ Tous les mod√®les sauvegard√©s avec succ√®s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error\n",
    "import pickle\n",
    "\n",
    "# ========== 1Ô∏è‚É£ Charger les donn√©es ==========\n",
    "\n",
    "df = pd.read_csv('gold_features_hourly_with_tp_sl.csv')\n",
    "print(\"‚úÖ Donn√©es charg√©es\")\n",
    "print(df.head())\n",
    "\n",
    "# ========== 2Ô∏è‚É£ S√©lection des features ==========\n",
    "\n",
    "features = [\n",
    "    'rsi', 'ema_9', 'ema_21', 'macd_line'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y_class = df['target']\n",
    "y_tp = df['target_up_move']\n",
    "y_sl = df['target_down_move']\n",
    "\n",
    "# ========== 3Ô∏è‚É£ Split des donn√©es ==========\n",
    "\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
    "    X, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_tp, y_test_tp, y_train_sl, y_test_sl = train_test_split(\n",
    "    X, y_tp, y_sl, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Split des donn√©es effectu√©\")\n",
    "\n",
    "# ========== 4Ô∏è‚É£ Entra√Æner les mod√®les ==========\n",
    "\n",
    "## üîπ Classifier (hausse ou baisse)\n",
    "clf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_model.fit(X_train_cls, y_train_cls)\n",
    "\n",
    "## üîπ Regressor pour TP\n",
    "tp_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "tp_model.fit(X_train_reg, y_train_tp)\n",
    "\n",
    "## üîπ Regressor pour SL\n",
    "sl_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "sl_model.fit(X_train_reg, y_train_sl)\n",
    "\n",
    "print(\"‚úÖ Entra√Ænement termin√©\")\n",
    "\n",
    "# ========== 5Ô∏è‚É£ Evaluation rapide ==========\n",
    "\n",
    "## üìå Classifier\n",
    "y_pred_cls = clf_model.predict(X_test_cls)\n",
    "print(\"\\n‚úÖ Classifier Accuracy:\", accuracy_score(y_test_cls, y_pred_cls))\n",
    "print(\"\\n‚úÖ Classification Report:\\n\", classification_report(y_test_cls, y_pred_cls))\n",
    "\n",
    "## üìå TP Regressor\n",
    "y_pred_tp = tp_model.predict(X_test_reg)\n",
    "print(\"\\n‚úÖ MAE Take-Profit:\", mean_absolute_error(y_test_tp, y_pred_tp))\n",
    "\n",
    "## üìå SL Regressor\n",
    "y_pred_sl = sl_model.predict(X_test_reg)\n",
    "print(\"\\n‚úÖ MAE Stop-Loss:\", mean_absolute_error(y_test_sl, y_pred_sl))\n",
    "\n",
    "# ========== 6Ô∏è‚É£ Sauvegarde des mod√®les ==========\n",
    "\n",
    "with open('ict_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_model, f)\n",
    "\n",
    "with open('ict_tp_model.pkl', 'wb') as f:\n",
    "    pickle.dump(tp_model, f)\n",
    "\n",
    "with open('ict_sl_model.pkl', 'wb') as f:\n",
    "    pickle.dump(sl_model, f)\n",
    "\n",
    "print(\"\\n‚úÖ Tous les mod√®les sauvegard√©s avec succ√®s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b5458-20a0-4919-aaac-b62a1ce93945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
